{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: gpu\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch as tr\n",
    "import os, argparse, logging, json, pickle\n",
    "from configs import Config\n",
    "from exp_context import ExperimentContext\n",
    "from base.hyperparams import Hyperparams as H\n",
    "\n",
    "print('mode:', 'gpu' if Config.use_gpu else 'cpu')\n",
    "\n",
    "if Config.use_gpu:\n",
    "    tr.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "args_str = '-hp base/hyperparams.py -d all -en exp14_node_split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Argument Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resume\": false, \n",
      "    \"exp_name\": \"exp14_node_split\", \n",
      "    \"hyperparams\": \"base/hyperparams.py\", \n",
      "    \"weights\": \"iter\", \n",
      "    \"gpu\": 0, \n",
      "    \"delete\": [\n",
      "        \"all\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-g', '--gpu', default=0, help='index of the gpu to be used. default: 0')\n",
    "parser.add_argument('-r', '--resume', nargs='?', const=True, default=False,\n",
    "                    help='if present, the training resumes from the latest step, '\n",
    "                         'for custom step number, provide it as argument value')\n",
    "parser.add_argument('-d', '--delete', nargs='+', default=[], choices=['logs', 'weights', 'results', 'all'],\n",
    "                    help='delete the entities')\n",
    "parser.add_argument('-w', '--weights', nargs='?', default='iter', choices=['iter', 'best_gen', 'best_pred'],\n",
    "                    help='weight type to load if resume flag is provided. default: iter')\n",
    "parser.add_argument('-hp', '--hyperparams', required=True, help='hyperparam class to use from HyperparamFactory')\n",
    "parser.add_argument('-en', '--exp_name', default=None, help='experiment name. if not provided, it is taken from Hyperparams')\n",
    "\n",
    "args = parser.parse_args(args_str.split())\n",
    "print(json.dumps(args.__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_flag = args.resume is not False\n",
    "gpu_idx = str(args.gpu)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Experiment Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading HP from file\n",
      "importing hyperparams base.hyperparams\n"
     ]
    }
   ],
   "source": [
    "ExperimentContext.set_context(args.hyperparams, args.exp_name)\n",
    "H = ExperimentContext.Hyperparams  # type: Hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Set Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "LOG_FORMAT = \"[{}: %(filename)s: %(lineno)3s] %(levelname)s: %(funcName)s(): %(message)s\".format(ExperimentContext.exp_name)\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clear Logs and Results based on the argument flags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[exp14_node_split: <ipython-input-7-a00023a52412>:   5] WARNING: <module>(): Deleting Logs...\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): rm -r ../experiments/exp14_node_split/logs\n",
      "[exp14_node_split: <ipython-input-7-a00023a52412>:  10] WARNING: <module>(): Deleting all results in ../experiments/exp14_node_split/results...\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): rm -r ../experiments/exp14_node_split/results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from paths import Paths\n",
    "from utils import bash_utils, model_utils\n",
    "\n",
    "if 'all' in args.delete or 'logs' in args.delete or resume_flag is False:\n",
    "    logger.warning('Deleting Logs...')\n",
    "    bash_utils.delete_recursive(Paths.logs_base_dir)\n",
    "    print('')\n",
    "\n",
    "if 'all' in args.delete or 'results' in args.delete:\n",
    "    logger.warning('Deleting all results in {}...'.format(Paths.results_base_dir))\n",
    "    bash_utils.delete_recursive(Paths.results_base_dir)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create required directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/results\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/logs\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/weights/saved/\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/weights/all/\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/results\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/results/.temp\n"
     ]
    }
   ],
   "source": [
    "model_utils.setup_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model and Training related imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.factory import DataLoaderFactory\n",
    "from base.hyperparams import Hyperparams\n",
    "\n",
    "from models.toy.gan import ToyGAN\n",
    "from models.toy.gt.gantree import GanTree\n",
    "from models.toy.gt.gnode import GNode\n",
    "from models.toy.gt.utils import GNodeUtils, DistParams\n",
    "\n",
    "from trainers.gan_trainer import GanTrainer\n",
    "from trainers.gan_trainer import TrainConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Tensorboard Port**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h5>\n",
       "    <b>Tensorboard hosted at \n",
       "        <a href=http://10.24.32.52:8001>10.24.32.52:8001</a>\n",
       "    </b>\n",
       "</h5>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip = bash_utils.get_ip_address()\n",
    "tboard_port = str(bash_utils.find_free_port(Config.base_port))\n",
    "bash_utils.launchTensorBoard(Paths.logs_base_dir, tboard_port)\n",
    "address = '{ip}:{port}'.format(ip=ip, port=tboard_port)\n",
    "address_str = 'http://{}'.format(address)\n",
    "tensorboard_msg = \"Tensorboard active at http://%s:%s\" % (ip, tboard_port)\n",
    "html_content = \"\"\"\n",
    "<h5>\n",
    "    <b>Tensorboard hosted at \n",
    "        <a href={}>{}</a>\n",
    "    </b>\n",
    "</h5>\n",
    "\"\"\".format(address_str, address)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Dump Hyperparams file the experiments directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_string_content = json.dumps(H.__dict__, default=lambda x: repr(x), indent=4, sort_keys=True)\n",
    "# print(hyperparams_string_content)\n",
    "with open(Paths.exp_hyperparams_file, \"w\") as fp:\n",
    "    fp.write(hyperparams_string_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Train Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(\n",
    "    n_step_tboard_log=50,\n",
    "    n_step_console_log=-1,\n",
    "    n_step_validation=100,\n",
    "    n_step_save_params=1000,\n",
    "    n_step_visualize=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create Gan Model and DataLoader for root GNode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = ToyGAN.create_from_hyperparams('node0', H, '+')\n",
    "dist_params = DistParams(gan.z_op_params[0], gan.z_op_params[1], 1.0, 1.0)\n",
    "dl = DataLoaderFactory.get_dataloader(H.dataloader, H.input_size, H.z_size, H.batch_size, H.batch_size, supervised=True)\n",
    "x_batch, _ = dl.random_batch('test', 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create Gan Tree and GNode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[exp14_node_split: utils.py:  44] INFO: create_child_node(): Child Node node0 created\n",
      "[exp14_node_split: utils.py:  45] INFO: create_child_node(): Node parameters: \n",
      "[exp14_node_split: utils.py:  46] INFO: create_child_node(): prior_means: tensor([0., 0.])\n",
      "[exp14_node_split: utils.py:  47] INFO: create_child_node(): prior_cov  : tensor([[1.0000, 0.6000],\n",
      "        [0.6000, 1.0000]])\n",
      "[exp14_node_split: utils.py:  48] INFO: create_child_node(): cond_prob  : 1.0\n",
      "[exp14_node_split: utils.py:  49] INFO: create_child_node(): abs_prob   : 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree = GanTree('gtree', ToyGAN, H, x_batch)\n",
    "gnode = tree.create_child_node(dist_params, gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Set Trainer for GNode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/weights/iter/node0\n",
      "[exp14_node_split: bash_utils.py:  10] INFO: exec_cmd(): mkdir -p ../experiments/exp14_node_split/weights/best/node0\n"
     ]
    }
   ],
   "source": [
    "gnode.set_trainer(dl, H, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h5>\n",
       "    <b>Tensorboard hosted at \n",
       "        <a href=http://10.24.32.52:8001>10.24.32.52:8001</a>\n",
       "    </b>\n",
       "</h5>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnode.train(10000)\n",
    "# gnode.save('split_node.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnode = GNode.load('split_node.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[exp14_node_split: utils.py:  59] INFO: split_node(): Starting Split Process: <GNode[name=node0 id=0 parent_id=-1]>\n",
      "[exp14_node_split: utils.py:  61] INFO: split_node(): Gaussian Mixture Fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: expected a matrix at /pytorch/aten/src/THC/generic/THCTensorMath.cu:395",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8c7567e69973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'splitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/models/toy/gt/gantree.pyc\u001b[0m in \u001b[0;36msplit_node\u001b[0;34m(self, parent, x_batch, fixed)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         child_nodes = GNodeUtils.split_node(parent, self.n_child, x_batch,\n\u001b[0;32m---> 53\u001b[0;31m                                             base_id=len(self.nodes), fixed=fixed)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/models/toy/gt/utils.pyc\u001b[0m in \u001b[0;36msplit_node\u001b[0;34m(parent, n_child, x_batch, base_id, fixed)\u001b[0m\n\u001b[1;32m     87\u001b[0m                                 \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                 \u001b[0mdisc_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                                 disc_z=parent.gan.disc_z.copy(),)\n\u001b[0m\u001b[1;32m     90\u001b[0m                                 \u001b[0;31m#z_bounds=parent.gan.z_bounds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/models/toy/gan.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, z_op_params, z_ip_params, encoder, decoder, disc_x, disc_z, z_bounds)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_op_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_ip_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mToyEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_bounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/modules/commons.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src_params, target_params)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_params\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mtarget_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleZTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleZTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/modules/commons.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mellipse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project_skeleton/gan-tree/src/utils/tr_utils.pyc\u001b[0m in \u001b[0;36mellipse_params\u001b[0;34m(cov)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 1: expected a matrix at /pytorch/aten/src/THC/generic/THCTensorMath.cu:395"
     ]
    }
   ],
   "source": [
    "if gnode.is_leaf:\n",
    "    tree.split_node(gnode, x_batch, fixed=False)\n",
    "    print ('splitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gnode.post_gmm_encode(dl.data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.gnode_trainer import GNodeTrainer\n",
    "trainer = GNodeTrainer(gnode, dl, H, train_config)\n",
    "trainer.relabel_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(100)\n",
    "# gnode.child_nodes[2].trainer.data_loader.data['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import viz_utils\n",
    "from scipy import stats\n",
    "style.use(style.available[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl.data['train']\n",
    "zdata = gnode.post_gmm_encode(data)\n",
    "print(gnode.predict_z(zdata))\n",
    "label = gnode.predict_x(data)\n",
    "colors = np.array(['red', 'blue'])[label-1]\n",
    "plt.scatter(zdata[:, 0], zdata[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_splits, i_splits = gnode.split_x(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "super(nn.Module, gnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gnode.child_nodes)\n",
    "node1, node2 = gnode.child_nodes.values()\n",
    "means = node1.prior_means, node2.prior_means\n",
    "cov = node1.prior_cov, node2.prior_cov\n",
    "\n",
    "print(means)\n",
    "print(cov[0])\n",
    "print(cov[1])\n",
    "\n",
    "f1 = stats.multivariate_normal(means[0], cov[0])\n",
    "f2 = stats.multivariate_normal(means[1], cov[1])\n",
    "\n",
    "ax = plt.gca()\n",
    "data1, data2 = x_splits[1], x_splits[2]\n",
    "z1 = node1.gan.encode(data1)\n",
    "z2 = node2.gan.encode(data2)\n",
    "\n",
    "print (z1.shape, z2.shape)\n",
    "\n",
    "print(f1.pdf(z1).mean())\n",
    "print(f2.pdf(z2).mean())\n",
    "\n",
    "e1 = viz_utils.get_ellipse(means[0], cov[0], [2], color='pink')\n",
    "e2 = viz_utils.get_ellipse(means[1], cov[1], [2], color='black')\n",
    "\n",
    "ax.set_xlim(-7, 7)\n",
    "ax.set_ylim(-7, 7)\n",
    "ax.scatter(z1[:, 0], z1[:, 1], color='red', s=1)\n",
    "ax.scatter(z2[:, 0], z2[:, 1], color='blue', s=1)\n",
    "for e in e1 + e2:\n",
    "    ax.add_artist(e)\n",
    "    \n",
    "# plt.scatter(data1[:, 0], data1[:, 1], color='red', s=1)\n",
    "# plt.scatter(data2[:, 0], data2[:, 1], color='blue', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = gnode.gmm.means_\n",
    "cov = gnode.gmm.covariances_\n",
    "\n",
    "f1 = stats.multivariate_normal(means[0], cov[0])\n",
    "f2 = stats.multivariate_normal(means[1], cov[1])\n",
    "\n",
    "ax = plt.gca()\n",
    "data1, data2 = x_splits[1], x_splits[2]\n",
    "z1 = gnode.gan.encode(data1)\n",
    "z2 = gnode.gan.encode(data2)\n",
    "\n",
    "print(f1.pdf(z1).mean())\n",
    "print(f2.pdf(z2).mean())\n",
    "\n",
    "e1 = viz_utils.get_ellipse(means[0], cov[0], [1, 2, 2.5], color='pink')\n",
    "e2 = viz_utils.get_ellipse(means[1], cov[1], [1, 2, 2.5], color='blue')\n",
    "\n",
    "ax.scatter(z1[:, 0], z1[:, 1], color='red', s=1)\n",
    "ax.scatter(z2[:, 0], z2[:, 1], color='blue', s=1)\n",
    "for e in e1 + e2:\n",
    "    ax.add_artist(e)\n",
    "# for e in e2:\n",
    "#     ax.add_artist(e)\n",
    "    \n",
    "# plt.scatter(data1[:, 0], data1[:, 1], color='red', s=1)\n",
    "# plt.scatter(data2[:, 0], data2[:, 1], color='blue', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gnode.gan.decode(np.random.normal(0, 1, (1000, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_batch = gnode.post_gmm_encode(x_batch)\n",
    "z_batch_ = gnode.gan.encode(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.n_components = 10\n",
    "A = np.random.uniform(-1, 1, (1000, 2))\n",
    "B = np.random.normal(1, 1/3.0, (1000, 2))\n",
    "C = np.concatenate([A, B])\n",
    "gmm.fit(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.predict_proba(C).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.style as style\n",
    "style.use(style.available[14])\n",
    "from matplotlib import  pyplot as plt\n",
    "ax = plt.gca()\n",
    "ax.scatter(C[:, 0], C[:, 1])\n",
    "\n",
    "e1 = viz_utils.get_ellipse(gmm.means_[0], gmm.covariances_[0], [1,2,3], color='orange')\n",
    "e2 = viz_utils.get_ellipse(gmm.means_[1], gmm.covariances_[1], [1,2,3], color='red')\n",
    "\n",
    "for e in e1 + e2:\n",
    "    ax.add_artist(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.toy import gantree\n",
    "from models.toy.gantree import GNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = GNode(model=gnode.gan)\n",
    "node.gmm.fit(dl.data['train'])\n",
    "node1, node2 = gantree.split_node(node, 2, x_batch, 1)\n",
    "x_splits, i_splits = node.split_x(dl.data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_splits[1]), len(x_splits[2])\n",
    "node1.dist_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_splits[1][:, 0], x_splits[1][:, 1], color='red', s=1)\n",
    "plt.scatter(x_splits[2][:, 0], x_splits[2][:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_loss(logits, labels):\n",
    "    if isinstance(labels, int):\n",
    "        if labels == 0.:\n",
    "            labels = tr.zeros_like(logits)\n",
    "        elif labels == 1.:\n",
    "            labels = tr.ones_like(logits)\n",
    "\n",
    "    losses = tr.max(logits, tr.zeros_like(logits)) - logits * labels + tr.log(1 + tr.exp(-tr.abs(logits)))\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tr.rand(1000,)\n",
    "labels = tr.randint(0, 2, (1000, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_cross_entropy_loss(logits, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(logits, tr.ones_like(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
